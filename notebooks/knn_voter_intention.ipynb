{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48d8b27f",
   "metadata": {},
   "source": [
    "\n",
    "# Modelo de intenci?n de voto con KNN\n",
    "\n",
    "Notebook preparado para Google Colab. Contexto: una campa?a pol?tica busca predecir la intenci?n de voto de nuevos electores a partir del dataset `voter_intentions_3000.csv` (~3000 filas, 33 columnas). El modelo principal es **K vecinos m?s cercanos** por su sencillez, interpretabilidad y porque permite exponer un servicio r?pido para prototipos.\n",
    "\n",
    "> Reglas: no cambiar los nombres de las columnas del CSV original. Las copias transformadas deben indicar claramente que son derivadas.\n",
    "\n",
    "Antes de ejecutar:\n",
    "1. Sube el archivo `voter_intentions_3000.csv` a la sesi?n de Colab o m?ntalo desde Drive.\n",
    "2. Verifica la ruta en la variable `DATA_PATH`.\n",
    "3. Ejecuta todo para generar el artefacto `models/knn_voter_intention_pipeline.pkl` que consumir? el backend.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cdb43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    f1_score,\n",
    ")\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "DATA_PATH = \"voter_intentions_3000.csv\"  # Ajusta esta ruta seg?n tu entorno\n",
    "MODEL_OUTPUT = Path(\"..\") / \"models\" / \"knn_voter_intention_pipeline.pkl\"\n",
    "MODEL_OUTPUT.parent.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f66637b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Carga del dataset original (no modifiques los nombres de columnas)\n",
    "df_raw = pd.read_csv(DATA_PATH)\n",
    "print(\"Dimensiones:\", df_raw.shape)\n",
    "df_raw.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2720cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tipos y primeros estadisticos b?sicos\n",
    "df_raw.info()\n",
    "\n",
    "df_raw.describe(include='all').transpose().head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bc6700",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Distribuci?n de la variable objetivo\n",
    "fig, ax = plt.subplots(figsize=(10,4))\n",
    "counts = df_raw['intended_vote'].value_counts().sort_values(ascending=False)\n",
    "counts.plot(kind='bar', ax=ax, color=\"#3D8B7D\")\n",
    "ax.set_title(\"Distribuci?n de intended_vote\")\n",
    "ax.set_ylabel(\"Conteo\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace3bacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revision de valores faltantes y estadisticos numericos\n",
    "missing_ratio = df_raw.isnull().mean().sort_values(ascending=False)\n",
    "print(\"Top columnas con mayor proporcion de NaN:\", missing_ratio.head(10))\n",
    "\n",
    "# Estadisticos basicos de numericas\n",
    "df_raw.describe().T[['mean', 'std', 'min', 'max']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8176adf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Gr?ficas simples\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15,4))\n",
    "\n",
    "axes[0].hist(df_raw['age'].dropna(), bins=20, color=\"#8FBC91\")\n",
    "axes[0].set_title(\"Histograma de edad\")\n",
    "axes[0].set_xlabel(\"Edad\")\n",
    "axes[0].set_ylabel(\"Frecuencia\")\n",
    "\n",
    "axes[1].scatter(df_raw['party_id_strength'], df_raw['preference_strength'], alpha=0.5, color=\"#3D8B7D\")\n",
    "axes[1].set_title(\"Party ID vs Preference Strength\")\n",
    "axes[1].set_xlabel(\"party_id_strength\")\n",
    "axes[1].set_ylabel(\"preference_strength\")\n",
    "\n",
    "axes[2].hist(df_raw['will_turnout'].dropna(), bins=15, color=\"#DBC557\")\n",
    "axes[2].set_title(\"Distribuci?n de will_turnout\")\n",
    "axes[2].set_xlabel(\"Probabilidad declarada\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0aa6b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definici?n de columnas\n",
    "TARGET = 'intended_vote'\n",
    "\n",
    "categorical_features = [\n",
    "    'gender', 'education', 'employment_status', 'employment_sector',\n",
    "    'income_bracket', 'marital_status', 'urbanicity', 'region',\n",
    "    'voted_last', 'has_children', 'union_member', 'public_sector',\n",
    "    'home_owner', 'small_biz_owner', 'owns_car', 'wa_groups',\n",
    "    'primary_choice', 'secondary_choice'\n",
    "]\n",
    "\n",
    "numeric_features = [\n",
    "    col for col in df_raw.columns if col not in categorical_features + [TARGET]\n",
    "]\n",
    "\n",
    "print(\"Categ?ricas:\", categorical_features)\n",
    "print(\"Num?ricas:\", numeric_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c778e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputacion simple y, si hay muchas ausencias, imputacion supervisada ligera\n",
    "\n",
    "df = df_raw.copy()\n",
    "missing_ratio = df.isnull().mean()\n",
    "high_missing = missing_ratio[missing_ratio > 0.15]\n",
    "print(\"Columnas con >15% de NaN (se intentara imputacion supervisada si es viable):\")\n",
    "print(high_missing)\n",
    "\n",
    "# Ejemplo: si preference_strength tiene huecos, usar regresion lineal como imputador supervisado\n",
    "if 'preference_strength' in high_missing.index:\n",
    "    try:\n",
    "        helper_features = [c for c in numeric_features if c != 'preference_strength']\n",
    "        train_mask = df['preference_strength'].notnull()\n",
    "        if train_mask.sum() > 20:\n",
    "            lin_reg = LinearRegression()\n",
    "            lin_reg.fit(df.loc[train_mask, helper_features].fillna(0), df.loc[train_mask, 'preference_strength'])\n",
    "            pred_mask = df['preference_strength'].isnull()\n",
    "            df.loc[pred_mask, 'preference_strength'] = lin_reg.predict(\n",
    "                df.loc[pred_mask, helper_features].fillna(0)\n",
    "            )\n",
    "            print(\"Imputacion supervisada aplicada a preference_strength con LinearRegression.\")\n",
    "    except Exception as exc:  # fallback a imputacion simple\n",
    "        print(\"Fallo imputacion supervisada, se mantiene estrategia simple:\", exc)\n",
    "\n",
    "# Para categoricas con muchos nulos se usa LogisticRegression si hay datos suficientes\n",
    "if 'voted_last' in high_missing.index:\n",
    "    try:\n",
    "        helper_features = numeric_features\n",
    "        train_mask = df['voted_last'].notnull()\n",
    "        if train_mask.sum() > 30:\n",
    "            log_reg = LogisticRegression(max_iter=200, multi_class='auto')\n",
    "            log_reg.fit(df.loc[train_mask, helper_features].fillna(0), df.loc[train_mask, 'voted_last'])\n",
    "            pred_mask = df['voted_last'].isnull()\n",
    "            df.loc[pred_mask, 'voted_last'] = log_reg.predict(\n",
    "                df.loc[pred_mask, helper_features].fillna(0)\n",
    "            )\n",
    "            print(\"Imputacion supervisada aplicada a voted_last con LogisticRegression.\")\n",
    "    except Exception as exc:\n",
    "        print(\"Fallo imputacion supervisada, se mantiene estrategia simple:\", exc)\n",
    "\n",
    "# El pipeline final seguira usando imputadores estadisticos para robustez en produccion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192edc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Divisi?n estratificada 70/15/15\n",
    "target_encoded = df[TARGET]\n",
    "X = df.drop(columns=[TARGET])\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, target_encoded, test_size=0.30, stratify=target_encoded, random_state=42\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, stratify=y_temp, random_state=42\n",
    ")\n",
    "print(\"Train:\", X_train.shape, \"Val:\", X_val.shape, \"Test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2115322d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Codificaci?n, escalado y clasificador KNN\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_enc = label_encoder.fit_transform(y_train)\n",
    "y_val_enc = label_encoder.transform(y_val)\n",
    "y_test_enc = label_encoder.transform(y_test)\n",
    "\n",
    "candidate_ks = [1, 3, 5, 7, 9, 11, 13, 15]\n",
    "val_scores = []\n",
    "\n",
    "for k in candidate_ks:\n",
    "    clf = KNeighborsClassifier(n_neighbors=k, weights=\"distance\")\n",
    "    model = Pipeline([\n",
    "        (\"preprocess\", preprocess),\n",
    "        (\"classifier\", clf),\n",
    "    ])\n",
    "    model.fit(X_train, y_train_enc)\n",
    "    preds = model.predict(X_val)\n",
    "    acc = accuracy_score(y_val_enc, preds)\n",
    "    f1 = f1_score(y_val_enc, preds, average=\"macro\")\n",
    "    val_scores.append({\"k\": k, \"val_accuracy\": acc, \"val_f1_macro\": f1})\n",
    "    print(f\"k={k} -> val_accuracy={acc:.3f}, val_f1_macro={f1:.3f}\")\n",
    "\n",
    "# Curva de desempe?o\n",
    "a_vals = [m['val_accuracy'] for m in val_scores]\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(candidate_ks, a_vals, marker='o', color=\"#3D8B7D\")\n",
    "plt.title(\"Accuracy de validaci?n vs K\")\n",
    "plt.xlabel(\"K vecinos\")\n",
    "plt.ylabel(\"Accuracy validaci?n\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "best_k = sorted(val_scores, key=lambda x: (-x['val_accuracy'], x['k']))[0]['k']\n",
    "print(\"Mejor K seleccionado:\", best_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d35b708",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Entrenar modelo final con train+val\n",
    "y_trainval = label_encoder.transform(pd.concat([y_train, y_val]))\n",
    "X_trainval = pd.concat([X_train, X_val])\n",
    "\n",
    "final_clf = KNeighborsClassifier(n_neighbors=best_k, weights=\"distance\")\n",
    "final_model = Pipeline([\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"classifier\", final_clf),\n",
    "])\n",
    "final_model.fit(X_trainval, y_trainval)\n",
    "\n",
    "test_preds = final_model.predict(X_test)\n",
    "test_acc = accuracy_score(y_test_enc, test_preds)\n",
    "test_f1 = f1_score(y_test_enc, test_preds, average=\"macro\")\n",
    "print(f\"Test accuracy: {test_acc:.3f} | Test F1 macro: {test_f1:.3f}\")\n",
    "\n",
    "print(\"\n",
    "Reporte de clasificaci?n en test:\")\n",
    "print(classification_report(y_test_enc, test_preds, target_names=label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c3d9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Matriz de confusi?n en prueba\n",
    "cm = confusion_matrix(y_test_enc, test_preds)\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "cax = ax.imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "ax.set_title('Matriz de confusi?n (test)')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xlabel('Predicci?n')\n",
    "ax.set_ylabel('Real')\n",
    "ax.set_xticks(range(len(label_encoder.classes_)))\n",
    "ax.set_yticks(range(len(label_encoder.classes_)))\n",
    "ax.set_xticklabels(label_encoder.classes_, rotation=45, ha='right')\n",
    "ax.set_yticklabels(label_encoder.classes_)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7192a401",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Guardar pipeline completo + metadatos\n",
    "metadata = {\n",
    "    \"model_type\": \"KNeighborsClassifier\",\n",
    "    \"k_value\": int(best_k),\n",
    "    \"metric\": final_model.named_steps['classifier'].metric,\n",
    "    \"weights\": final_model.named_steps['classifier'].weights,\n",
    "    \"trained_at\": pd.Timestamp.utcnow().isoformat(),\n",
    "    \"train_size\": len(X_trainval),\n",
    "    \"val_accuracy\": float([m['val_accuracy'] for m in val_scores if m['k'] == best_k][0]),\n",
    "    \"test_accuracy\": float(test_acc),\n",
    "    \"feature_columns\": list(X.columns),\n",
    "    \"classes\": label_encoder.classes_.tolist(),\n",
    "    \"notes\": \"Pipeline con imputaci?n simple + one-hot + escalado + KNN. Re-entrenar con datos reales antes de produccion.\",\n",
    "}\n",
    "\n",
    "bundle = {\n",
    "    \"pipeline\": final_model,\n",
    "    \"label_encoder_classes\": label_encoder.classes_.tolist(),\n",
    "    \"metadata\": metadata,\n",
    "}\n",
    "\n",
    "joblib.dump(bundle, MODEL_OUTPUT)\n",
    "print(f\"Modelo guardado en {MODEL_OUTPUT.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8476ec",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusiones y pr?ximos pasos\n",
    "\n",
    "- El modelo KNN muestra su desempe?o seg?n las m?tricas de validaci?n/prueba. Valores bajos pueden deberse a clases minoritarias o a la clase \"Undecided\".\n",
    "- K m?s altos suelen estabilizar el ruido; K bajos capturan m?s variabilidad pero pueden sobreajustar perfiles raros.\n",
    "- Limita el uso a fines educativos. Para una campa?a real: recolectar m?s datos, balancear clases y revisar continuamente el desempe?o.\n",
    "- El artefacto `models/knn_voter_intention_pipeline.pkl` debe copiarse al repositorio del backend para que los endpoints `/predict` funcionen.\n",
    "- Comparte este notebook como p?blico en Colab para que el equipo pueda reentrenar cuando se actualice el CSV.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
